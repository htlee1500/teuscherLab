# imports
import snntorch as snn
from snntorch import spikeplot as splt
from snntorch import spikegen
import snntorch.functional as snnfunc

import torch
import torch.nn as nn

import numpy as np
import matplotlib.pyplot as plt
import math

from torch.utils.data import DataLoader
from torchvision import datasets, transforms

import flif_snn
import random
import timeit


def main():
        
        device = torch.device("cuda") if torch.cuda.is_available() else torch.device("mps") if torch.backends.mps.is_available() else torch.device("cpu")
        scale = 10
        num_input = scale*scale
        num_hidden1 = 1000
        num_hidden2 = 750
        num_output = 10

        num_steps = 200


        net = flif_snn.SNN(num_input, num_hidden1, num_output, num_steps, device).to(device)

        loader = np.load("MNIST_Training/parameters.npz", allow_pickle = True)
        hid_con = loader['hid_con']
        out_con = loader['out_con']

        hid_con = torch.tensor(hid_con).to(device)
        out_con = torch.tensor(out_con).to(device)

        success = net.load(hid_con, out_con)
        
        if success == -1:
                quit()

        loader = np.load("MNIST_Training/dataset.npz", allow_pickle = True)
        all_data = torch.tensor(loader['dat']).to(device)
        all_targets = torch.tensor(loader['tar']).to(device)
        print("Data loaded successfully")
        
        num_batches = all_targets.size(0)


        num_samples = 100
        num_deleted = 20

        accuracy = np.zeros((num_deleted, num_samples))

        print("Beginning testing")
        for i in range(num_deleted):

                for j in range(num_samples):

                        start = timeit.default_timer()
                        
                        deleted = [random.randint(0, num_input-1) for k in range(i)]
                        acc = 0
                        for batch in range(num_batches):

                                data = all_data[batch].clone()

                                for neuron in deleted:

                                        data[:, neuron] = torch.zeros_like(data[:, neuron])
                                
                                targets = all_targets[batch]

                                spikes, _, _ = net(data, targets, False)

                                acc += snnfunc.acc.accuracy_rate(spikes, targets)

                        acc = acc / num_batches
                        
                        accuracy[i][j] = acc

                        end = timeit.default_timer()
                        print(f"Sample {j} completed for {i} deletions. Time elapsed: {end-start}")
        

        np.savez("MNIST_Training/mc_dead.npz", acc=accuracy)
        print("Saved data.")

                        
                

if __name__ == '__main__':
        main()
